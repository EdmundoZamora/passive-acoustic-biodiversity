{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sounddevice as sd\n",
    "import pylab as pl\n",
    "import random\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from adjustText import adjust_text\n",
    "from collections import Counter\n",
    "from scipy.io.wavfile import write\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import ShortTermFeatures\n",
    "\n",
    "import librosa\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "import tempfile\n",
    "from pydub.utils import which\n",
    "from scipy.io.wavfile import write\n",
    "import scipy\n",
    "import warnings \n",
    "\n",
    "AudioSegment.converter = which(\"ffmpeg\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns all clip indexes within a cluster\n",
    "def get_clip_indexes(cluster_label, clusters):\n",
    "    clips_i = []\n",
    "    for i in range(len(clusters)):\n",
    "        if clusters[i] == cluster_label:\n",
    "            clips_i.append(i)\n",
    "    return clips_i\n",
    "\n",
    "# Plays a random clip in a given cluster\n",
    "def play_random_clip_in_cluster(index, clusters, option='cluster'):\n",
    "    assert(option == 'cluster' or option == 'clip')\n",
    "    if option == 'clip':\n",
    "        index = find_cluster(index, clusters) # Get cluster index\n",
    "    \n",
    "    clips = get_clip_indexes(index, clusters)\n",
    "    clip_i = clips[random.randint(0, len(clips) - 1)]\n",
    "    print('Playing clip index %d ' % clip_i)\n",
    "    play_clip(clip_i)\n",
    "        \n",
    "# Returns the cluster label that a clip belongs to\n",
    "def find_cluster(clip_index, clusters):\n",
    "    return clusters[clip_index]\n",
    "\n",
    "# Plays an audio clip given the clip index\n",
    "def play_clip(clip_index):\n",
    "    samples = shorter_clips[clip_index]\n",
    "    sd.play(samples, samplerate)\n",
    "\n",
    "# Flattens a given list\n",
    "def list_flatten(l):\n",
    "    flat_list = []\n",
    "    for sublist in l:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "# Saves clip as a wav file\n",
    "def save_clip(filename, wav_array):\n",
    "    assert('.' not in filename)\n",
    "    write(filename + '.wav', samplerate, wav_array)\n",
    "    \n",
    "# Saves all clips to a directory\n",
    "def save_clips_to_dir(shorter_clips, dirname):\n",
    "    for i, clip in enumerate(shorter_clips):\n",
    "        save_clip(dirname + '/%d' % i, clip) \n",
    "            \n",
    "def convert_mp3_to_wav(mp3_path, sr=44100, mono=True, overwrite=False, dtype='float32'): \n",
    "    # Need to change sample rate to 44.1kHz if using audiomoths\n",
    "    # since mono=True by default, unless you pass mono=False, \n",
    "    # this function will save the wav as mono\n",
    "#     print(\"entering convert_mp3_to_wav\")\n",
    "    \"\"\"\n",
    "    Parts of code from \n",
    "    https://github.com/bill317996/Audio-to-midi/blob/master/cfp.py\n",
    "    \"\"\"\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "    \n",
    "    # in case there is an .MP3\n",
    "    assert mp3_path.lower().endswith('.mp3'), 'filename indicates not mp3'\n",
    "    wav_path_to_write = os.path.splitext(mp3_path)[0] + '.wav'\n",
    "#     print(wav_path_to_write)\n",
    "    \n",
    "    if not overwrite and os.path.exists(wav_path_to_write):\n",
    "        print(\"ah\")\n",
    "        return\n",
    "    \n",
    "    mp3 = AudioSegment.from_file(mp3_path)\n",
    "    \n",
    "    _, temp_path = tempfile.mkstemp() \n",
    "    mp3.export(temp_path, format='wav')\n",
    "    print(temp_path)\n",
    "    del mp3\n",
    "    x, fs = sf.read(temp_path)\n",
    "    os.remove(temp_path)\n",
    "    \n",
    "    if mono and len(x.shape)>1: \n",
    "        x = np.mean(x, axis = 1) \n",
    "    if sr:\n",
    "        x = scipy.signal.resample_poly(x, sr, fs)\n",
    "        fs = sr \n",
    "    x = x.astype(dtype)\n",
    "#     print(fs)\n",
    "    write(wav_path_to_write, fs, x)\n",
    "    return x, fs\n",
    "\n",
    "def read(f, normalized=False):\n",
    "    \"\"\"MP3 to numpy array\"\"\"\n",
    "    a = pydub.AudioSegment.from_file(f)\n",
    "    y = np.array(a.get_array_of_samples())\n",
    "    if a.channels == 2:\n",
    "        y = y.reshape((-1, 2))\n",
    "    if normalized:\n",
    "        return a.frame_rate, np.float32(y) / 2**15\n",
    "    else:\n",
    "        return a.frame_rate, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Testing load_audio function\n",
    "\n",
    "dir_path = '/Volumes/Elements/Madre_de_Dios_Xeno_Canto_Birdcalls/'\n",
    "file_path = dir_path + 'XC431125 - Rufous Twistwing - Cnipodectes superrufus.mp3'\n",
    "# file_path = dir_path + 'XC91323 - White-eyed Parakeet - Psittacara leucophthalmus.mp3'\n",
    "\n",
    "x, fs = convert_mp3_to_wav(file_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs to sanity check output of load_audio with online mp3 to wav converter \n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(x)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# This file is from a random mp3 to wav convert I found here\n",
    "# https://online-audio-converter.com/ and then downloaded on Desktop\n",
    "check_dir_path = '/Users/yoo-jin/Desktop/XC431125 - Rufous Twistwing - Cnipodectes superrufus.wav'\n",
    "x_test, fs_test = sf.read(check_dir_path)\n",
    "\n",
    "x_test = np.mean(x_test, axis = 1) \n",
    "print(x_test.shape)\n",
    "\n",
    "ax2.plot(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how many files have 44.1kHz vs 48kHz sampling rates in Xeno Canto\n",
    "num_441k = 0 \n",
    "num_48k = 0\n",
    "for f in glob.glob(os.path.join(dir_path, '*.mp3')):\n",
    "#     print(f)\n",
    "#     print(num_441k)\n",
    "#     print(num_48k)\n",
    "    rate, sound = read(f)\n",
    "    if rate == 44100: \n",
    "        num_441k = num_441k + 1\n",
    "    elif rate == 48000:\n",
    "        num_48k = num_48k + 1\n",
    "        \n",
    "print(num_441k)\n",
    "print(num_48k) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_path = '/Volumes/Elements/Madre_de_Dios_Xeno_Canto_Birdcalls/'\n",
    "samplerate = None\n",
    "wav_data = []\n",
    "wav_names = []\n",
    "\n",
    "for file in glob.glob(os.path.join(dir_path, '*.mp3')):\n",
    "#     print(file)\n",
    "#     convert_mp3_to_wav(file, overwrite=True)\n",
    "    \n",
    "    try: \n",
    "        data, rate = convert_mp3_to_wav(file, overwrite=True)\n",
    "#         data = data.astype(int)\n",
    "        samplerate = rate\n",
    "        if wav_data == []:\n",
    "            wav_data = data\n",
    "        else:\n",
    "            wav_data = np.concatenate((wav_data, data))\n",
    "        clip_len = len(data) / samplerate\n",
    "        \n",
    "        # Input only bird species\n",
    "        bird_species_name = file.split(' - ')[2][:-4].replace(' ', '_')\n",
    "        wav_names.append((bird_species_name, clip_len))\n",
    "        print(file)\n",
    "        # TO DO: deal with deprecation warning, don't suppress\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "    except Exception as e:\n",
    "        print('(failed) ' + file)\n",
    "        print('\\t' + str(e))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(wav_data.shape)\n",
    "# print(wav_data)\n",
    "print(samplerate)\n",
    "print(type(wav_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('number of channels = %d' % wav_data.shape[1]) \n",
    "# print(np.shape(wav_data))\n",
    "# print('number of channels = %d' % np.shape(wav_data)) \n",
    "\n",
    "print('sample rate = %d' % samplerate)\n",
    "length = wav_data.shape[0] / samplerate\n",
    "print('length = %.1fs' % length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get n-minute clips\n",
    "def split_into_minutes(wav_data, samplerate, n=1):\n",
    "    length_in_seconds = len(wav_data) / samplerate\n",
    "    length_in_minutes = length_in_seconds / 60\n",
    "    length_in_minutes = int(length_in_minutes / n)\n",
    "\n",
    "    cut_wav_data = wav_data[:-((len(wav_data)) % length_in_minutes)]\n",
    "    shorter_clips = np.split(cut_wav_data, length_in_minutes)\n",
    "    print('%d %d-minute clips' % (len(shorter_clips), n))\n",
    "    return shorter_clips\n",
    "\n",
    "# Get n-second clips\n",
    "def split_into_n_seconds(wav_data, wav_names, samplerate, n=10):\n",
    "    \"\"\"\n",
    "    wav_names =\n",
    "    [\n",
    "       ('Olive-faced_Flatbill':10), ('Olive-faced_Flatbill':2), ('Channel-billed_Toucan':8)\n",
    "    ]\n",
    "    file_names =\n",
    "    [\n",
    "        Olive-faced_Flatbill_Split.wav,\n",
    "        Olive-faced_Flatbill2_Channel-billed_Toucan8.wav\n",
    "    ]\n",
    "    \"\"\"\n",
    "    file_names = []\n",
    "    \n",
    "    length_in_seconds = len(wav_data) / samplerate\n",
    "    length_in_minutes = length_in_seconds / 60\n",
    "    length_in_minutes = int(length_in_minutes)\n",
    "    shorter_len = int(length_in_minutes / (1/(60/n)))\n",
    "    \n",
    "    second_clips = None\n",
    "    \n",
    "    try:\n",
    "        second_clips = np.split(wav_data, shorter_len)\n",
    "    except:\n",
    "        cut_wav_data = wav_data[:-((len(wav_data)) % shorter_len)]\n",
    "        second_clips = np.split(cut_wav_data, shorter_len)\n",
    "\n",
    "    # wav_name[0][0]=\"Versasilles birdopolus\", wav_name[0][1]=12\n",
    "    # wav_name[1][0]=\"Amazilia lactea\",        wav_name[1][1]=9\n",
    "    # wav_name[2][0]=\"Ramphastos vitellinus\",  wav_name[2][1]=7\n",
    "    # 'Versasilles_birdopolus_Split.wav', 'Versasilles_birdopolus2_Amazilia_lactea_Split.wav', 'Ramphastos_vitellinus7_Split.wav'\n",
    "\n",
    "    i = 0\n",
    "    amount_left = 0\n",
    "    while i < len(wav_names):\n",
    "        # create new clip from just one bird\n",
    "        if wav_names[i][1] >= n and amount_left == 0:\n",
    "            file_names.append(wav_names[i][0] + \"_Split.wav\")\n",
    "            wav_names[i][1] -= n\n",
    "        \n",
    "        # create new clip and leave it unfinished\n",
    "        elif 0 < wav_names[i][1] < n and amount_left == 0:\n",
    "            file_names.append(wav_names[i][0] + str(wav_names[i][1]) + \"_\")\n",
    "            amount_left = n - wav_names[i][1]\n",
    "            wav_names[i][1] = 0\n",
    "            \n",
    "        # finish prev clip\n",
    "        elif wav_names[i][1] >= amount_left and amount_left > 0:\n",
    "            file_names[-1] += wav_names[i][0] + \"_Split.wav\"\n",
    "            wav_names[i][1] -= amount_left\n",
    "            amount_left = 0\n",
    "        \n",
    "        # if length is 0\n",
    "        elif wav_names[i][1] == 0:\n",
    "            i+=1\n",
    "    \n",
    "    file_names[-1] += \"_Split.wav\"\n",
    "    \n",
    "    print('%d %d-second clips' % (len(second_clips), n))\n",
    "    return second_clips\n",
    "\n",
    "#             # if not last clip\n",
    "#             if i < len(wav_names)-1:\n",
    "#                 name = wav_names[i][0] + (wav_names[i][1] % n) + \"_\" + \\\n",
    "#                         wav_names[i+1][0] + (wav_names[i+1][1] % n) + \".wav\"\n",
    "#                 file_names.append(name)\n",
    "#             else: \n",
    "#                 name = wav_names[i][0] + (wav_names[i][1] % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#shorter_clips = split_into_minutes(wav_data, samplerate, 1)\n",
    "\n",
    "shorter_clips, file_names = split_into_n_seconds(wav_data, wav_names, samplerate, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(samplerate, shorter_clips, clip_index, separate_channels=False):\n",
    "    left_channel = shorter_clips[clip_index][:, 0]\n",
    "    right_channel = shorter_clips[clip_index][:, 1]\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (100, 100)\n",
    "    plt.rcParams.update({'font.size': 50})\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    if separate_channels:\n",
    "        plt.title('Clip #%d (Left Channel)' % clip_index)\n",
    "        plt.specgram(left_channel, Fs=samplerate)\n",
    "        plt.subplot(212)\n",
    "        plt.title('Clip #%d (Right Channel)' % clip_index)\n",
    "        plt.specgram(right_channel, Fs=samplerate)\n",
    "    else:\n",
    "        plt.title('Clip #%d' % clip_index)\n",
    "        both_channels = left_channel + right_channel\n",
    "        plt.specgram(both_channels, Fs=samplerate)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_spectrogram_of_cluster(samplerate, shorter_clips, cluster_i, clusters, separate_channels=False):\n",
    "    clip_indexes = get_clip_indexes(cluster_i, clusters)\n",
    "    \n",
    "    left_channel = shorter_clips[clip_indexes[0]][:, 0]\n",
    "    right_channel = shorter_clips[clip_indexes[0]][:, 1]\n",
    "    \n",
    "    for i in range(1, len(clip_indexes)):\n",
    "        left_channel = np.append(left_channel, shorter_clips[clip_indexes[i]][:, 0])\n",
    "        right_channel = np.append(right_channel, shorter_clips[clip_indexes[i]][:, 1])\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (100, 100)\n",
    "    plt.rcParams.update({'font.size': 50})\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    if separate_channels:\n",
    "        plt.title('Cluster #%d (Left Channel)' % cluster_i)\n",
    "        plt.specgram(left_channel, Fs=samplerate)\n",
    "        plt.subplot(212)\n",
    "        plt.title('Cluster #%d (Right Channel)' % cluster_i)\n",
    "        plt.specgram(right_channel, Fs=samplerate)\n",
    "    else:\n",
    "        plt.title('Cluster #%d' % cluster_i)\n",
    "        both_channels = left_channel + right_channel\n",
    "        plt.specgram(both_channels, Fs=samplerate)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: isn't working with mp3 \n",
    "# plot_spectrogram(samplerate, shorter_clips)\n",
    "\n",
    "# This is working with xeno canto data\n",
    "\n",
    "plt.specgram(x, Fs=samplerate)\n",
    "# plt.specgram(wav_data, Fs=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Add a way to select and evaluate features\n",
    "\n",
    "def extract_features(shorter_clips, mfcc_only=False, mono=False):\n",
    "    feat_clips = []\n",
    "\n",
    "    print('Extracting features for each of the %d audio clips' % len(shorter_clips))\n",
    "    for clip in shorter_clips:\n",
    "        if mono == False:\n",
    "            clip = clip[:, 0] + clip[:, 1] # Merging left and right channels\n",
    "\n",
    "        mfcc_feat=None\n",
    "        if mfcc_only:\n",
    "            mfcc_feat = mfcc(clip, samplerate, winlen=0.023, nfft = 1024).flatten()\n",
    "\n",
    "        else:\n",
    "            mfcc_feat = ShortTermFeatures.feature_extraction(clip, samplerate, 0.050*samplerate, 0.025*samplerate)\n",
    "            print('')\n",
    "            print(mfcc_feat[1])\n",
    "\n",
    "        # Append the features\n",
    "        if mfcc_only:\n",
    "            feat_clips.append(mfcc_feat)\n",
    "        else:\n",
    "            feat_clips.append(list_flatten(mfcc_feat[0]))\n",
    "\n",
    "    print('done')\n",
    "    return feat_clips\n",
    "    \n",
    "# Set mfcc_only to True to shorten runtime\n",
    "mfcc_clips = extract_features(shorter_clips, mfcc_only=True, mono=True)\n",
    "#all_feat_clips = extract_features(shorter_clips)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 1 - cosine_similarity(mfcc_clips)\n",
    "mds = PCA(n_components=2, random_state=1)\n",
    "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "\n",
    "X = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X, 'single')\n",
    "\n",
    "labelList = range(len(X))\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "dendro = dendrogram(linked,\n",
    "#             p=7,\n",
    "            orientation='top',\n",
    "            #labels=labelList,\n",
    "            truncate_mode='level',\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cluster_plot(pos, title='', without_labels=False, width=20, height=20, savepath=''):\n",
    "    plt.rc('font', size=15)\n",
    "    \n",
    "    xs, ys = pos[:, 0], pos[:, 1]\n",
    "    \n",
    "    labels = range(len(shorter_clips))\n",
    "\n",
    "    # Data frame with TSNE data, the cluster numbers and titles\n",
    "    cluster_df = pd.DataFrame(dict(x=xs, y=ys, clusters=clusters, labels=labels)) \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(width, height))\n",
    "    ax.margins(0.05)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    groups = cluster_df.groupby('clusters')\n",
    "    for name, group in groups:\n",
    "        ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, mec='none', label=name)\n",
    "        ax.set_aspect('auto')\n",
    "        ax.tick_params(axis= 'x', which='both', bottom='off', top='off', labelbottom='off')\n",
    "        ax.tick_params(axis= 'y', which='both', left='off', top='off', labelleft='off')\n",
    "\n",
    "    ax.legend(numpoints=1)\n",
    "    ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "\n",
    "    #Add labels\n",
    "    if not without_labels:\n",
    "        texts = []\n",
    "        for i in range(len(cluster_df)):\n",
    "            texts.append(ax.text(cluster_df.loc[i, 'x'], cluster_df.loc[i, 'y'], cluster_df.loc[i,'labels'], size=10)) \n",
    "\n",
    "        #adjust_text(texts, arrowprops=dict(arrowstyle='->', color='red'))\n",
    "    \n",
    "    if savepath != '':\n",
    "        plt.savefig(savepath, dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for K-means clustering only, the elbow would be the ideal number of clusters to use\n",
    "\n",
    "# TODO: plot.ly\n",
    "\n",
    "def find_optimal_clusters(data, min_k, max_k): \n",
    "    iters= range(min_k, max_k+1, 2)\n",
    "    \n",
    "    sse = [] \n",
    "    for k in iters: \n",
    "        sse.append(MiniBatchKMeans(n_clusters=k, init_size=1024, batch_size=2048, random_state=20).fit(data).inertia_)\n",
    "        \n",
    "    f, ax = plt.subplots(1,1)\n",
    "    ax.plot(iters, sse, marker = 'o')\n",
    "    ax.set_xlabel('Cluster Centers')\n",
    "#     ax.set_xticks(iters)\n",
    "#     f.autofmt_xdate()\n",
    "#     ax.set_xtickslabels(iters)\n",
    "    ax.set_ylabel('SSE')\n",
    "    ax.set_title('SSE by Number of Clusters')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "        \n",
    "find_optimal_clusters(X, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose number of clusters\n",
    "# TO DO: need to choose the correct number of clusters\n",
    "n_clusters = 16\n",
    "\n",
    "# Fit clustering model\n",
    "clusters = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward').fit_predict(mfcc_clips)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.savefig(savepath, dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the bird species \n",
    "\n",
    "dir_path = '/Volumes/Elements/Madre_de_Dios_Xeno_Canto_Birdcalls/'\n",
    "list_of_species = []\n",
    "\n",
    "# for f in glob.glob(os.path.join(dir_path, '*.mp3')):\n",
    "\n",
    "for f in glob.glob(os.path.join(dir_path, '*.mp3')): \n",
    "    bird_name = os.path.splitext(f)[0].split(\" - \", 1)[1].strip()\n",
    "    if list_of_species == []: \n",
    "        list_of_species = [bird_name]\n",
    "    elif bird_name in list_of_species: \n",
    "        pass \n",
    "    else: \n",
    "        list_of_species.append(bird_name)\n",
    "\n",
    "# list_of_species = np.array(list_of_species)\n",
    "\n",
    "print(list_of_species)\n",
    "print(len(list_of_species))\n",
    "# print(list_of_species.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Project the data onto 2D graph - 10 clusters\n",
    "dist = 1 - cosine_similarity(mfcc_clips)\n",
    "mds = PCA(n_components=2, random_state=1)\n",
    "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "\n",
    "# /Volumes/Elements/Madre_de_Dios_Xeno_Canto_Birdcalls/\n",
    "\n",
    "cluster_plot(pos, 'PCA Cluster Plot', without_labels=True, savepath='/Volumes/Elements/Madre_de_Dios_Xeno_Canto_Birdcalls/Clusters_XenoCanto/pca.png')\n",
    "spe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the data onto 2D graph - 10 clusters\n",
    "dist = 1 - cosine_similarity(mfcc_clips)\n",
    "mds = TSNE(n_components=2, random_state=1)\n",
    "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "\n",
    "cluster_plot(pos, 'TSNE Cluster Plot', without_labels=True, savepath='/Volumes/Elements/Madre_de_Dios_Xeno_Canto_Birdcalls/Clusters_XenoCanto/tsne.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prints: (Cluster number, count of clips in cluster)\n",
    "Counter(clusters).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_random_clip_in_cluster(6, clusters) # Play random clip in a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.stop() # Stop playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can assign a label to each cluster here\n",
    "#cluster_names = ['quiet', 'loud', 'quiet', 'rain', 'birds', 'crickets', 'birds', 'quiet', 'quiet', 'loud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See clip indexes of all clips inside cluster\n",
    "clip_indexes = get_clip_indexes(0, clusters)\n",
    "print(clip_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_clip(36) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all clusters\n",
    "dirname = '/Volumes/Elements/Madre_de_Dios_Xeno_Canto_Birdcalls/Clusters_XenoCanto/'\n",
    "\n",
    "# TODO: play around with number of clusters\n",
    "n_clusters = 134\n",
    "\n",
    "# Fit clustering model\n",
    "clusters = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward').fit_predict(mfcc_clips)\n",
    "print(type(clusters))\n",
    "print(clusters.shape)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Saves clip as a wav file\n",
    "def save_clip(filename, wav_array):\n",
    "    assert('.' not in filename)\n",
    "    write(filename + '.wav', samplerate, wav_array)\n",
    "\"\"\"\n",
    "\n",
    "# TODO; figure out a way to preserve the original file names\n",
    "\"\"\"\n",
    "wav_names =\n",
    "[\n",
    "   {'Olive-faced_Flatbill':10}, {'Olive-faced_Flatbill':2, 'Channel-billed_Toucan':8}\n",
    "]\n",
    "file_names =\n",
    "[\n",
    "    Olive-faced_Flatbill_Split.wav,\n",
    "    Olive-faced_Flatbill2_Channel-billed_Toucan8.wav\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# Edited code \n",
    "for i in range(len(np.unique(clusters))):\n",
    "    # if file already exists, then delete it and overwrite it\n",
    "    os.mkdir(dirname + 'cluster_%d' % i)\n",
    "    \n",
    "    \n",
    "    for j in get_clip_indexes(i, clusters):\n",
    "        save_clip(dirname + 'cluster_%d/%d' % (i, j), shorter_clips[j]) \n",
    "\n",
    "# # Erika's original code \n",
    "# for i in range(len(np.unique(clusters))):\n",
    "#     # if file already exists, then delete it and overwrite it\n",
    "    \n",
    "#     os.mkdir(dirname + 'cluster_%d' % i)\n",
    "#     for j in get_clip_indexes(i, clusters):\n",
    "#         save_clip(dirname + 'cluster_%d/%d' % (i, j), shorter_clips[j]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spectrogram of all clips in a cluster appended together\n",
    "plot_spectrogram_of_cluster(samplerate, shorter_clips, 7, clusters, separate_channels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clips = len(shorter_clips)\n",
    "num_minutes = num_clips / 6\n",
    "num_hours = num_minutes / 60\n",
    "\n",
    "def clip_i_to_bin_i(clip_i):\n",
    "    return int(clip_i / (num_clips/num_minutes))\n",
    "\n",
    "def time_hist_for_cluster(cluster_i, clusters):\n",
    "    hist_data = []\n",
    "    for index in get_clip_indexes(cluster_i, clusters):\n",
    "        index = clip_i_to_bin_i(index)\n",
    "        hist_data.append(index)\n",
    "\n",
    "    plt.ylim(0, (num_clips/num_minutes))\n",
    "    plt.title('Cluster: %d (%s)' % (cluster_i, cluster_names[cluster_i]))\n",
    "    plt.hist(hist_data, bins=int(num_minutes), range=[0, num_minutes])\n",
    "    plt.show()\n",
    "    \n",
    "def colors(n):\n",
    "    ret = []\n",
    "    r = int(random.random() * 256)\n",
    "    g = int(random.random() * 256)\n",
    "    b = int(random.random() * 256)\n",
    "    step = 256 / n\n",
    "    for i in range(n):\n",
    "        r += step\n",
    "        g += step\n",
    "        b += step\n",
    "        r = int(r) % 256\n",
    "        g = int(g) % 256\n",
    "        b = int(b) % 256\n",
    "        ret.append((r,g,b)) \n",
    "    return ret\n",
    "\n",
    "def get_clusters_by_cluster_names(clusters, cluster_names):\n",
    "    uniq_names = np.unique(cluster_names)\n",
    "    print(uniq_names)\n",
    "    new_clusters = [-1] * len(clusters)\n",
    "    for uniq_name_i, uniq_name in enumerate(uniq_names):\n",
    "        for name_i, name in enumerate(cluster_names):\n",
    "            if name == uniq_name:\n",
    "                # Assign name_i to each index in the cluster that has the same index\n",
    "                for index in range(len(clusters)):\n",
    "                    if clusters[index] == name_i:\n",
    "                        new_clusters[index] = uniq_name_i\n",
    "    return new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_clusters = get_clusters_by_cluster_names(clusters, cluster_names)\n",
    "Counter(named_clusters).most_common() \n",
    "cluster_names_to_plot = np.unique(cluster_names)\n",
    "\n",
    "# Colors for visualization\n",
    "jet = pl.get_cmap('jet', len(cluster_names_to_plot))\n",
    "cluster_colors = {}\n",
    "for i, name in enumerate(cluster_names_to_plot):\n",
    "    cluster_colors[name] = jet(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: These are not real labels for the clusters, this is just a demonstration of the code. The histogram visualization will be replaced with better visualizations for cluster/time data such as Rose Plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_histograms(clusters, cluster_names):\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    for cluster_i in range(len(cluster_names)):\n",
    "        hist_data = []\n",
    "        for index in get_clip_indexes(cluster_i, clusters):\n",
    "            index = clip_i_to_bin_i(index)\n",
    "            hist_data.append(index)\n",
    "\n",
    "        cluster_name = cluster_names[cluster_i]\n",
    "        c = cluster_colors[cluster_name]\n",
    "        plt.hist(hist_data, bins=int(num_minutes), range=[0, num_minutes], alpha=0.5, color=c, label=cluster_name)\n",
    "\n",
    "        plt.ylabel('Number of 10-second audio clips')\n",
    "        plt.xlabel('Time in Minutes')\n",
    "        plt.legend(bbox_to_anchor=(1.2, 1.05))\n",
    "        plt.show()\n",
    "    \n",
    "clusters_to_plot = named_clusters\n",
    "cluster_names_to_plot = np.unique(cluster_names)\n",
    "plot_all_histograms(named_clusters, np.unique(cluster_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
